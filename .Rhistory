cat("\nFold", i, "Training set size:", length(train_index), "Test set size:", length(test_index), "\n")
train_data <- data[train_index, ]
train_y <- target[train_index]
test_data <- data[test_index, ]
test_y <- target[test_index]
# Fit linear model for each fold
linear_model <- lm(train_y ~ ., data = train_data)
# Print model summary for the current fold
cat("\n\n--- Model Summary for Fold", i, "---\n")
print(summary(linear_model))
# Make predictions on the test set for each fold
y_pred_linear <- predict(linear_model, newdata = test_data)
# Back-transform predictions to the original scale
y_pred_linear_backtransformed <- exp(y_pred_linear) - 1
test_y_backtransformed <- exp(test_y) - 1
# Calculate evaluation metrics for each fold
mae_values <- c(mae_values, mae(test_y_backtransformed, y_pred_linear_backtransformed))
mse_values <- c(mse_values, mse(test_y_backtransformed, y_pred_linear_backtransformed))
rmse_values <- c(rmse_values, rmse(test_y_backtransformed, y_pred_linear_backtransformed))
# Calculate residuals on log-transformed scale and fitted values
fold_residuals_log <- test_y - y_pred_linear
fold_fitted_values <- y_pred_linear
# Append residuals and fitted values from this fold to the overall vectors
all_residuals_log <- c(all_residuals_log, fold_residuals_log)
all_fitted_values <- c(all_fitted_values, fold_fitted_values)
}
# Calculate average metrics across all folds
mae_avg <- mean(mae_values)
mse_avg <- mean(mse_values)
rmse_avg <- mean(rmse_values)
# Print the cross-validation results
print(paste("Average MAE (original scale):", mae_avg))
print(paste("Average MSE (original scale):", mse_avg))
print(paste("Average RMSE (original scale):", rmse_avg))
# Plot Residuals vs Fitted (Log Scale)
plot(all_fitted_values, all_residuals_log,
main = "Residuals vs Fitted (Cross-Validation, Log Scale)",
xlab = "Fitted Values (Log Scale)",
ylab = "Residuals (Log Scale)")
abline(h = 0, col = "red")
# Q-Q Plot of residuals (Log Scale)
qqnorm(all_residuals_log, main = "Q-Q Plot of Residuals (Cross-Validation, Log Scale)")
qqline(all_residuals_log, col = "red")
# Return average metrics as a list
return(list(mae = mae_avg, mse = mse_avg, rmse = rmse_avg))
}
# Prepare dataset and target variable
data <- airquality_transformed[, !(names(airquality_transformed) %in% c("C6H6_GT"))]
target <- airquality_transformed$C6H6_GT
# Set number of folds
folds <- 10
# Perform cross-validation
cv_results <- cv_linear_model(data, target, folds)
# Plot setup
n <- nrow(data)  # Total number of data points
fold_size <- floor(n / folds)  # Size of each test set
plot(1, type = "n", xlim = c(1, n), ylim = c(1, folds),
xlab = "Data Index", ylab = "Fold",
main = "Training and Test Set Splits for Each Fold (Sliding Window)")
# Loop over each fold to define train and test splits with equal test size
for (i in 1:folds) {
# Define test indices for each fold
test_index <- ((i - 1) * fold_size + 1):(i * fold_size)
# Define training indices as all data except the current fold's test set
train_index <- setdiff(1:n, test_index)
# Plot training set as blue lines
segments(x0 = train_index, y0 = rep(i, length(train_index)),
x1 = train_index, y1 = rep(i, length(train_index)),
col = "blue", lwd = 2)
# Plot test set as red lines
segments(x0 = test_index, y0 = rep(i, length(test_index)),
x1 = test_index, y1 = rep(i, length(test_index)),
col = "red", lwd = 2)
}
#### Perform expending window Cross-Validation for linear model ####
cv_linear_model <- function(data, target, folds) {
n <- nrow(data)
fold_size <- floor(n / folds)
mae_values <- c()
mse_values <- c()
rmse_values <- c()
all_residuals_log <- c()
all_fitted_values <- c()
for (i in 1:folds) {
# Define expanding window for training and the next segment for testing
train_index <- 1:(fold_size * i)
test_index <- (fold_size * i + 1):min(n, fold_size * (i + 1))
# Only proceed if there’s enough data left for a test set
if (length(test_index) < fold_size) break
train_data <- data[train_index, ]
train_y <- target[train_index]
test_data <- data[test_index, ]
test_y <- target[test_index]
linear_model <- lm(train_y ~ ., data = train_data)
# Print model summary for the current fold
cat("\n\n--- Model Summary for Fold", i, "---\n")
print(summary(linear_model))
# Predictions and metrics as before
y_pred_linear <- predict(linear_model, newdata = test_data)
y_pred_linear_backtransformed <- exp(y_pred_linear) - 1
test_y_backtransformed <- exp(test_y) - 1
# Calculate evaluation metrics for each fold
mae_value <- mean(abs(test_y_backtransformed - y_pred_linear_backtransformed))
mse_value <- mean((test_y_backtransformed - y_pred_linear_backtransformed)^2)
rmse_value <- sqrt(mse_value)
# Store metrics
mae_values <- c(mae_values, mae_value)
mse_values <- c(mse_values, mse_value)
rmse_values <- c(rmse_values, rmse_value)
# Calculate residuals on log-transformed scale and fitted values
fold_residuals_log <- test_y - y_pred_linear
fold_fitted_values <- y_pred_linear
# Append residuals and fitted values from this fold to the overall vectors
all_residuals_log <- c(all_residuals_log, fold_residuals_log)
all_fitted_values <- c(all_fitted_values, fold_fitted_values)
}
# Calculate average metrics across all folds
mae_avg <- mean(mae_values)
mse_avg <- mean(mse_values)
rmse_avg <- mean(rmse_values)
# Print the cross-validation results
cat("\n\n--- Cross-Validation Results ---\n")
print(paste("Average MAE (original scale):", mae_avg))
print(paste("Average MSE (original scale):", mse_avg))
print(paste("Average RMSE (original scale):", rmse_avg))
# Plot Residuals vs Fitted (Log Scale)
plot(all_fitted_values, all_residuals_log,
main = "Residuals vs Fitted (Cross-Validation, Log Scale)",
xlab = "Fitted Values (Log Scale)",
ylab = "Residuals (Log Scale)")
abline(h = 0, col = "red")
# Q-Q Plot of residuals (Log Scale)
qqnorm(all_residuals_log, main = "Q-Q Plot of Residuals (Cross-Validation, Log Scale)")
qqline(all_residuals_log, col = "red")
# Return average metrics as a list
return(list(mae = mae_avg, mse = mse_avg, rmse = rmse_avg))
}
# Prepare dataset and target variable
data <- airquality_transformed[, !(names(airquality_transformed) %in% c("C6H6_GT"))]
target <- airquality_transformed$C6H6_GT
# Set number of folds
folds <- 10
# Perform cross-validation
cv_results <- cv_linear_model(data, target, folds)
# Plot setup
n <- nrow(data)  # Total number of data points
fold_size <- floor(n / folds)  # Size of each test set
plot(1, type = "n", xlim = c(1, n), ylim = c(1, folds),
xlab = "Data Index", ylab = "Fold",
main = "Training and Test Set Splits for Each Fold (Expanding Window)")
for (i in 1:folds) {
train_index <- 1:(fold_size * i)
test_index <- (fold_size * i + 1):min(n, fold_size * (i + 1))
if (length(test_index) < fold_size) break
# Training set in blue
segments(x0 = train_index, y0 = rep(i, length(train_index)),
x1 = train_index, y1 = rep(i, length(train_index)),
col = "blue", lwd = 2)
# Test set in red
segments(x0 = test_index, y0 = rep(i, length(test_index)),
x1 = test_index, y1 = rep(i, length(test_index)),
col = "red", lwd = 2)
}
legend("bottomright", legend = c("Training Set", "Test Set"),
col = c("blue", "red"), lty = 1, lwd = 2)
comparison_table <- data.frame(
Metric = c(
"MAE",
"MSE",
"RMSE",
),
linear_model = c(
mae_value,
mse_value,
rmse_value
),
Cross_Validation_Model = c(
mae_avg,
mse_avg,
rmse_avg
)
)
comparison_table <- data.frame(
Metric = c(
"MAE",
"MSE",
"RMSE"
),
linear_model = c(
mae_value,
mse_value,
rmse_value
),
Cross_Validation_Model = c(
mae_avg,
mse_avg,
rmse_avg
)
)
mae_avg
mean(mae_values)
### Cross Validation ####
#### Perform expending window Cross-Validation for linear model ####
cv_linear_model <- function(data, target, folds) {
n <- nrow(data)
fold_size <- floor(n / folds)
mae_values <- c()
mse_values <- c()
rmse_values <- c()
all_residuals_log <- c()
all_fitted_values <- c()
for (i in 1:folds) {
# Define expanding window for training and the next segment for testing
train_index <- 1:(fold_size * i)
test_index <- (fold_size * i + 1):min(n, fold_size * (i + 1))
# Only proceed if there’s enough data left for a test set
if (length(test_index) < fold_size) break
train_data <- data[train_index, ]
train_y <- target[train_index]
test_data <- data[test_index, ]
test_y <- target[test_index]
linear_model <- lm(train_y ~ ., data = train_data)
# Print model summary for the current fold
cat("\n\n--- Model Summary for Fold", i, "---\n")
print(summary(linear_model))
# Predictions and metrics as before
y_pred_linear <- predict(linear_model, newdata = test_data)
y_pred_linear_backtransformed <- exp(y_pred_linear) - 1
test_y_backtransformed <- exp(test_y) - 1
# Calculate evaluation metrics for each fold
mae_value <- mean(abs(test_y_backtransformed - y_pred_linear_backtransformed))
mse_value <- mean((test_y_backtransformed - y_pred_linear_backtransformed)^2)
rmse_value <- sqrt(mse_value)
# Store metrics
mae_values <- c(mae_values, mae_value)
mse_values <- c(mse_values, mse_value)
rmse_values <- c(rmse_values, rmse_value)
# Calculate residuals on log-transformed scale and fitted values
fold_residuals_log <- test_y - y_pred_linear
fold_fitted_values <- y_pred_linear
# Append residuals and fitted values from this fold to the overall vectors
all_residuals_log <- c(all_residuals_log, fold_residuals_log)
all_fitted_values <- c(all_fitted_values, fold_fitted_values)
}
# Calculate average metrics across all folds
mae_avg <- mean(mae_values)
mse_avg <- mean(mse_values)
rmse_avg <- mean(rmse_values)
# Print the cross-validation results
cat("\n\n--- Cross-Validation Results ---\n")
print(paste("Average MAE (original scale):", mae_avg))
print(paste("Average MSE (original scale):", mse_avg))
print(paste("Average RMSE (original scale):", rmse_avg))
# Plot Residuals vs Fitted (Log Scale)
plot(all_fitted_values, all_residuals_log,
main = "Residuals vs Fitted (Cross-Validation, Log Scale)",
xlab = "Fitted Values (Log Scale)",
ylab = "Residuals (Log Scale)")
abline(h = 0, col = "red")
# Q-Q Plot of residuals (Log Scale)
qqnorm(all_residuals_log, main = "Q-Q Plot of Residuals (Cross-Validation, Log Scale)")
qqline(all_residuals_log, col = "red")
# Return average metrics as a list
return(list(mae = mae_avg, mse = mse_avg, rmse = rmse_avg))
}
rmse_avg
cv_linear_model$mae_avg
comparison_table <- data.frame(
Metric = c(
"MAE",
"MSE",
"RMSE"
),
linear_model = c(
mae_value,
mse_value,
rmse_value
),
Cross_Validation_Model = c(
cv_linear_model[mae_avg],
mse_avg,
rmse_avg
)
)
# Perform cross-validation
cv_results <- cv_linear_model(data, target, folds)
mae_cv_value <- 1.54369075550381  # Replace with actual MAE from your linear model
mse_cv_value <- 8.30417782888116  # Replace with actual MSE from your linear model
rmse_cv_value <- 2.64138117820677
comparison_table <- data.frame(
Metric = c(
"MAE",
"MSE",
"RMSE"
),
linear_model = c(
mae_value,
mse_value,
rmse_value
),
Cross_Validation_Model = c(
mae_avg,
mse_avg,
rmse_avg
)
)
comparison_table <- data.frame(
Metric = c(
"MAE",
"MSE",
"RMSE"
),
linear_model = c(
mae_value,
mse_value,
rmse_value
),
Cross_Validation_Model = c(
mae_cv_avg,
mse_cv_avg,
rmse_cv_avg
)
)
comparison_table <- data.frame(
Metric = c(
"MAE",
"MSE",
"RMSE"
),
linear_model = c(
mae_value,
mse_value,
rmse_value
),
Cross_Validation_Model = c(
mae_cv_value,
mse_cv_value,
rmse_cv_value
)
)
# Print the comparison table
print(comparison_table)
comparison_table <- data.frame(
Metric = c(
"MAE",
"MSE",
"RMSE"
),
Linear_model = c(
mae_value,
mse_value,
rmse_value
),
Cross_Validation_Model = c(
mae_cv_value,
mse_cv_value,
rmse_cv_value
)
)
write.csv(comparison_table, file = "model_comparison.csv", row.names = FALSE)
# Print the comparison table
print(comparison_table)
# Perform cross-validation
cv_results <- cv_linear_model(data, target, folds)
### Cross Validation ####
#### Perform expending window Cross-Validation for linear model ####
cv_linear_model <- function(data, target, folds) {
n <- nrow(data)
fold_size <- floor(n / folds)
mae_values <- c()
mse_values <- c()
rmse_values <- c()
all_residuals_log <- c()
all_fitted_values <- c()
for (i in 1:folds) {
# Define expanding window for training and the next segment for testing
train_index <- 1:(fold_size * i)
test_index <- (fold_size * i + 1):min(n, fold_size * (i + 1))
# Only proceed if there’s enough data left for a test set
if (length(test_index) < fold_size) break
# Print the size of training and test sets for each fold
cat("\nFold", i, "Training set size:", length(train_index), "Test set size:", length(test_index), "\n")
train_data <- data[train_index, ]
train_y <- target[train_index]
test_data <- data[test_index, ]
test_y <- target[test_index]
linear_model <- lm(train_y ~ ., data = train_data)
# Print model summary for the current fold
cat("\n\n--- Model Summary for Fold", i, "---\n")
print(summary(linear_model))
# Predictions and metrics as before
y_pred_linear <- predict(linear_model, newdata = test_data)
y_pred_linear_backtransformed <- exp(y_pred_linear) - 1
test_y_backtransformed <- exp(test_y) - 1
# Calculate evaluation metrics for each fold
mae_value <- mean(abs(test_y_backtransformed - y_pred_linear_backtransformed))
mse_value <- mean((test_y_backtransformed - y_pred_linear_backtransformed)^2)
rmse_value <- sqrt(mse_value)
# Store metrics
mae_values <- c(mae_values, mae_value)
mse_values <- c(mse_values, mse_value)
rmse_values <- c(rmse_values, rmse_value)
# Calculate residuals on log-transformed scale and fitted values
fold_residuals_log <- test_y - y_pred_linear
fold_fitted_values <- y_pred_linear
# Append residuals and fitted values from this fold to the overall vectors
all_residuals_log <- c(all_residuals_log, fold_residuals_log)
all_fitted_values <- c(all_fitted_values, fold_fitted_values)
}
# Calculate average metrics across all folds
mae_avg <- mean(mae_values)
mse_avg <- mean(mse_values)
rmse_avg <- mean(rmse_values)
# Print the cross-validation results
cat("\n\n--- Cross-Validation Results ---\n")
print(paste("Average MAE (original scale):", mae_avg))
print(paste("Average MSE (original scale):", mse_avg))
print(paste("Average RMSE (original scale):", rmse_avg))
# Plot Residuals vs Fitted (Log Scale)
plot(all_fitted_values, all_residuals_log,
main = "Residuals vs Fitted (Cross-Validation, Log Scale)",
xlab = "Fitted Values (Log Scale)",
ylab = "Residuals (Log Scale)")
abline(h = 0, col = "red")
# Q-Q Plot of residuals (Log Scale)
qqnorm(all_residuals_log, main = "Q-Q Plot of Residuals (Cross-Validation, Log Scale)")
qqline(all_residuals_log, col = "red")
# Return average metrics as a list
return(list(mae = mae_avg, mse = mse_avg, rmse = rmse_avg))
}
# Prepare dataset and target variable
data <- airquality_transformed[, !(names(airquality_transformed) %in% c("C6H6_GT"))]
target <- airquality_transformed$C6H6_GT
# Set number of folds
folds <- 10
# Perform cross-validation
cv_results <- cv_linear_model(data, target, folds)
# Perform cross-validation
cv_results <- cv_linear_model(data, target, folds)
### Cross Validation ####
#### Perform expending window Cross-Validation for linear model ####
cv_linear_model <- function(data, target, folds) {
n <- nrow(data)
fold_size <- floor(n / folds)
mae_values <- c()
mse_values <- c()
rmse_values <- c()
all_residuals_log <- c()
all_fitted_values <- c()
for (i in 1:folds) {
# Define expanding window for training and the next segment for testing
train_index <- 1:(fold_size * i)
test_index <- (fold_size * i + 1):min(n, fold_size * (i + 1))
# Only proceed if there’s enough data left for a test set
if (length(test_index) < fold_size) break
train_data <- data[train_index, ]
train_y <- target[train_index]
test_data <- data[test_index, ]
test_y <- target[test_index]
linear_model <- lm(train_y ~ ., data = train_data)
# Print model summary for the current fold
cat("\n\n--- Model Summary for Fold", i, "---\n")
print(summary(linear_model))
# Print the size of training and test sets for each fold
cat("\nFold", i, "Training set size:", length(train_index), "Test set size:", length(test_index), "\n")
# Predictions and metrics as before
y_pred_linear <- predict(linear_model, newdata = test_data)
y_pred_linear_backtransformed <- exp(y_pred_linear) - 1
test_y_backtransformed <- exp(test_y) - 1
# Calculate evaluation metrics for each fold
mae_value <- mean(abs(test_y_backtransformed - y_pred_linear_backtransformed))
mse_value <- mean((test_y_backtransformed - y_pred_linear_backtransformed)^2)
rmse_value <- sqrt(mse_value)
# Store metrics
mae_values <- c(mae_values, mae_value)
mse_values <- c(mse_values, mse_value)
rmse_values <- c(rmse_values, rmse_value)
# Calculate residuals on log-transformed scale and fitted values
fold_residuals_log <- test_y - y_pred_linear
fold_fitted_values <- y_pred_linear
# Append residuals and fitted values from this fold to the overall vectors
all_residuals_log <- c(all_residuals_log, fold_residuals_log)
all_fitted_values <- c(all_fitted_values, fold_fitted_values)
}
# Calculate average metrics across all folds
mae_avg <- mean(mae_values)
mse_avg <- mean(mse_values)
rmse_avg <- mean(rmse_values)
# Print the cross-validation results
cat("\n\n--- Cross-Validation Results ---\n")
print(paste("Average MAE (original scale):", mae_avg))
print(paste("Average MSE (original scale):", mse_avg))
print(paste("Average RMSE (original scale):", rmse_avg))
# Plot Residuals vs Fitted (Log Scale)
plot(all_fitted_values, all_residuals_log,
main = "Residuals vs Fitted (Cross-Validation, Log Scale)",
xlab = "Fitted Values (Log Scale)",
ylab = "Residuals (Log Scale)")
abline(h = 0, col = "red")
# Q-Q Plot of residuals (Log Scale)
qqnorm(all_residuals_log, main = "Q-Q Plot of Residuals (Cross-Validation, Log Scale)")
qqline(all_residuals_log, col = "red")
# Return average metrics as a list
return(list(mae = mae_avg, mse = mse_avg, rmse = rmse_avg))
}
# Prepare dataset and target variable
data <- airquality_transformed[, !(names(airquality_transformed) %in% c("C6H6_GT"))]
target <- airquality_transformed$C6H6_GT
# Set number of folds
folds <- 10
# Perform cross-validation
cv_results <- cv_linear_model(data, target, folds)
